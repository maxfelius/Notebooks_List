{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatio-temporal Clip With top view and Bar plot\n",
    "@author: Max Felius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, time\n",
    "import re, datetime\n",
    "from scipy import spatial\n",
    "from tqdm import tqdm\n",
    "\n",
    "#import personal functions\n",
    "sys.path.extend(os.path.join(os.getcwd(),'sinkhole_functions'))\n",
    "from sinkhole_functions.functions import *\n",
    "from sinkhole_functions.influence_functions import *\n",
    "from sinkhole_functions.spatio_temporal_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = ''\n",
    "filename1 = 'Implemented_linear_Franciscanerstraat_sinkhole_final.csv'\n",
    "# filename1 = 'Subset_MRSS_s1_asc_t88_x0203050.00_y0318500.00_r500m.csv'\n",
    "# filename1 = 'Sinkhole_Implemented_Dataset_3.csv'\n",
    "# filename1 = 'Subset_MRSS_s1_asc_t88_x0_203050.00_y0_318500.00_r100m.csv'\n",
    "location_file = 'sinkhole_kerkrade.csv'\n",
    "\n",
    "#load the data\n",
    "data = pd.read_csv(os.path.join(folder,filename1))\n",
    "location = pd.read_csv(os.path.join(folder,location_file))\n",
    "\n",
    "location_gdf = gpd.GeoDataFrame(location, geometry=gpd.points_from_xy(location.longitude, location.latitude))\n",
    "location_gdf.crs = 'epsg:4326' #wgs84\n",
    "location_gdf = location_gdf.to_crs('epsg:28992') # to Amersfoort Rijksdriehoekenstelsel\n",
    "\n",
    "# #---------------------#\n",
    "# #make the kdtree for quick subset creation\n",
    "# rdx = data['pnt_rdx'].values\n",
    "# rdy = data['pnt_rdy'].values\n",
    "# rd_data = np.concatenate((rdx.reshape(len(rdx),1),rdy.reshape(len(rdy),1)),axis=1)\n",
    "# tree = spatial.cKDTree(rd_data)\n",
    "\n",
    "# x0 = location_gdf.geometry.x.values[0]\n",
    "# y0 = location_gdf.geometry.y.values[0]\n",
    "\n",
    "# #cropping the dataset\n",
    "# subset = tree.query_ball_point(([x0,y0]),r=80)\n",
    "# data = data.iloc[subset]\n",
    "# #-------------------#\n",
    "\n",
    "\n",
    "#get information from pandas df\n",
    "headers = list(data)\n",
    "data_gdf = gpd.GeoDataFrame(data, geometry=gpd.points_from_xy(data.pnt_lon, data.pnt_lat))\n",
    "data_gdf.crs = 'epsg:4326' #wgs84\n",
    "data_gdf = data_gdf.to_crs('epsg:28992') #to Amersfoort Rijksdriehoekenstelsel\n",
    "\n",
    "\n",
    "#select point locations\n",
    "rdx = data_gdf.geometry.x.values\n",
    "rdy = data_gdf.geometry.y.values\n",
    "\n",
    "#make the kdtree for quick subset creation\n",
    "rd_data = np.concatenate((rdx.reshape(len(rdx),1),rdy.reshape(len(rdy),1)),axis=1)\n",
    "tree = spatial.cKDTree(rd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 35\n",
    "epoch_vector = np.array([10])\n",
    "\n",
    "#obtain limits dataset\n",
    "xmin = np.min(rdx)\n",
    "xmax = np.max(rdx)\n",
    "ymin = np.min(rdy)\n",
    "ymax = np.max(rdy)\n",
    "\n",
    "#Define the grid for evaluation\n",
    "n = 40\n",
    "x_len = xmax-xmin\n",
    "y_len = ymax-ymin\n",
    "x_range = np.linspace(xmin+(0.1*x_len),xmax-(0.1*x_len),n)\n",
    "y_range = np.linspace(ymin+(0.1*y_len),ymax-(0.1*y_len),n)\n",
    "\n",
    "xv, yv = np.meshgrid(x_range,y_range)\n",
    "xv_u = xv.ravel()\n",
    "yv_u = yv.ravel()\n",
    "\n",
    "epochs = np.array(get_sentinel_days(list(data_gdf))) #get all the sentinel epochs\n",
    "\n",
    "#save the data\n",
    "save_folder = f'new_clip_spatioTemp_final_{n}x{n}_{epoch_vector[0]}n_R{R}'\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.255507571720227"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-xmin+xmax)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/1: 100%|██████████| 1600/1600 [08:46<00:00,  3.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# epoch_vector = np.array([10,15,20])\n",
    "epoch_xhat = []\n",
    "epoch_qxhat = []\n",
    "\n",
    "for idx,nepoch in enumerate(epoch_vector): #number of epochs used\n",
    "    # setting up variables\n",
    "    n_points = len(xv_u)\n",
    "    n_time = nepoch\n",
    "    #define the time window of a sinkhole\n",
    "    steps = np.arange(0,len(epochs)-n_time,1)\n",
    "    n_steps = len(steps)\n",
    "\n",
    "    # pre allocate space for variable\n",
    "    xhat_save = np.zeros((n_points,n_steps))\n",
    "    qxhat_save = np.zeros((n_points,n_steps))\n",
    "    fxhat_save = np.zeros((n_points,n_steps))\n",
    "    fqxhat_save = np.zeros((n_points,n_steps))\n",
    "\n",
    "    #start the grid-wise search\n",
    "    for i in tqdm(range(n_points),f'{idx+1}/{len(epoch_vector)}'):\n",
    "        #select new center point\n",
    "        xi = xv_u[i]\n",
    "        yi = yv_u[i]\n",
    "\n",
    "        #select subset\n",
    "        subset = tree.query_ball_point(([xi,yi]),r=R)\n",
    "\n",
    "        #start test\n",
    "        if len(subset) <= 1: \n",
    "            #subset is empty\n",
    "            for iii in range(n_steps):\n",
    "                xhat_save[i,iii] = np.nan\n",
    "                qxhat_save[i,iii] = np.nan\n",
    "        else:\n",
    "            #compute distance towards center (radius)\n",
    "            xp = data_gdf.geometry.x.values[subset]\n",
    "            yp = data_gdf.geometry.y.values[subset]\n",
    "\n",
    "            r = np.sqrt((xp-xi)**2 + (yp-yi)**2)\n",
    "\n",
    "            for ii in steps:\n",
    "                ii = int(ii)\n",
    "                #get relative days\n",
    "                selected_epochs = epochs[ii:ii+n_time]\n",
    "                t, start_day = get_delta_days(selected_epochs)\n",
    "\n",
    "                y = data_gdf[selected_epochs].iloc[subset].values\n",
    "\n",
    "                #calculate subsidence velocity\n",
    "                t_vector, y_vector, r_vector = create_matching_len(t,y,r)\n",
    "\n",
    "                xhat, Qxhat, fit = kinematic_model(R,r_vector,y_vector,t_vector)\n",
    "\n",
    "                #save the parameters\n",
    "                xhat_save[i,ii] = xhat\n",
    "                qxhat_save[i,ii] = Qxhat\n",
    "                fqxhat_save[i,ii] = filter_extremes2(Qxhat,maxvalue=1e-4,minvalue=0)\n",
    "#                 fxhat_save[i,ii] = filter_extremes(xhat,maxvalue=-0.0001,minvalue=-0.001)\n",
    "                fxhat_save[i,ii] = filter_extremes(xhat,maxvalue=0,minvalue=-0.0006)\n",
    "    \n",
    "    epoch_xhat.append(fxhat_save)\n",
    "    epoch_qxhat.append(fqxhat_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "cmin =0\n",
    "cmax =0.0006\n",
    "start= 80\n",
    "number_text=0.0001 #show only values above this threshold\n",
    "\n",
    "#import image\n",
    "img = plt.imread('background.png')\n",
    "extents = (xmin, xmax, ymin, ymax)\n",
    "\n",
    "#convert epochs into datetime object\n",
    "epoch_sel = np.array(list(map(lambda e: datetime.datetime.strptime(e,'d_%Y%m%d'),epochs)))\n",
    "\n",
    "#defining epochs used\n",
    "epoch_range = np.arange(epoch_vector[0]+start,len(epoch_sel)-epoch_vector[0],1)\n",
    "\n",
    "for epoch_selec in epoch_range:\n",
    "    fig, ax = plt.subplots(ncols=2,figsize=(15,10))\n",
    "\n",
    "    fig.suptitle(f'Epoch selected: {epoch_sel[epoch_selec+epoch_vector[0]]}')\n",
    "    \n",
    "    #apply filters\n",
    "    number = 0.0001 #filter number 2\n",
    "#     number = 0\n",
    "    filter_epoch_values = -fxhat_save[:,epoch_selec]\n",
    "    a = filter_epoch_values>number\n",
    "    b = fqxhat_save[:,epoch_selec] > 0\n",
    "    color_grid = [i and j for i, j in zip(a,b)]\n",
    "    \n",
    "    #---------first plot--------------#\n",
    "    ax[0].imshow(img,extent=extents)\n",
    "    ax[0].scatter(rdx,rdy,c='r',s=5,label='Observations')\n",
    "    \n",
    "#     color_grid = -fxhat_save[:,epoch_selec]\n",
    "\n",
    "#     number = 0\n",
    "    h = ax[0].scatter(xv_u[color_grid],yv_u[color_grid],c=filter_epoch_values[color_grid],vmin=cmin,vmax=cmax)#,s=70)\n",
    "    plt.colorbar(h,ax=ax[0])\n",
    "    \n",
    "    for idx,item in enumerate(color_grid):\n",
    "        if item:\n",
    "#     numbers = range(len(xv_u))\n",
    "#             ax[0].text(xv_u[idx],yv_u[idx],s=f'{idx}')\n",
    "            pass\n",
    "    \n",
    "    #admin stuff\n",
    "    ax[0].set_xlabel('Distance East [m]')\n",
    "    ax[0].set_ylabel('Distance North [m]')\n",
    "    ax[0].legend()\n",
    "    \n",
    "    #---------second plot--------------#\n",
    "    for idx,values in enumerate(zip(range(len(xv_u)),filter_epoch_values)):\n",
    "        i,j = values\n",
    "        if color_grid[idx]:\n",
    "            ax[1].bar(i,j,color='b')#filter_epoch_values[idx],vmin=cmin,vmax=cmax)\n",
    "            if j>number_text:\n",
    "    #             print(j,number,j>number)\n",
    "#                 ax[1].text(idx,j,s=f'{idx}')\n",
    "                pass\n",
    "    \n",
    "#     ax[1].bar(range(len(xv_u)),filter_epoch_values)\n",
    "    \n",
    "#     for idx,item in enumerate(filter_epoch_values[color_grid]):\n",
    "#         if item>number:\n",
    "#             ax[1].text(idx,item,s=f'{idx}')\n",
    "       \n",
    "    \n",
    "    #admin stuff\n",
    "    ax[1].set_ylim([cmin,cmax])\n",
    "    ax[1].set_xlabel('Point ID')\n",
    "    ax[1].set_ylabel('Subsidence Velocity [m/day]')\n",
    "    ax[1].set_xlim([0,len(xv_u)])\n",
    "    ax[1].grid(True)\n",
    "    \n",
    "#     break\n",
    "    plt.savefig(os.path.join(save_folder,'{:02d}_{}.png'.format(epoch_selec,epoch_sel[epoch_selec+epoch_vector[0]].strftime('%Y-%m-%d'))))\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create a vide\n",
    "`ffmpeg -framerate 2 -pattern_type glob -i '*.png' -vcodec libx264 -pix_fmt yuv420p -vb 20M spatio_temp_method.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-12-31'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_sel[epoch_selec+epoch_vector[0]].strftime('%Y-%m-%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
